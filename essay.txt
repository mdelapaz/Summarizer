This paper takes an interesting look at how we develop artificial intelligence systems for adversarial games, starting with an overview of more traditional AI agents (minimax, optimizing win conditions, etc.) and then focusing on their primary thesis which is the idea that rather than designing AI agents for the sole purpose of beating a human opponent, we should consider designing agents which make the game play more engaging and fun for the human. 
Some traditional methods for making AI agents accessible to human players are simply evolutionary versions of the agents designed to win.  For example, an AI designed to win at chess by analyzing the state space could be made “beatable” or more reasonable for less experienced players by either reducing its search depth (so it “sees” a very limited number of turns ahead) or introducing random errors (where the agent takes a sub-optimal branch on occasion).  While these can be effective tools, the results often leave the game feeling inauthentic (“why did the AI sacrifice that piece for no reason?”).  The authors posit that a better approach would be for the AI to act as a storyteller or director, guiding the game down paths that may not be optimal but do make the game more interesting for the human playing.  This can mean a number of things depending on what the AI developer decides is “interesting”.  Following the chess example, perhaps it means offering a gambit that reduces the AI’s chance of winning, but leads to a more dynamic game or it could mean working toward a position that provides the human an opportunity to exploit tactical advantages (pins, discovered checks, forks, etc.).  The idea is that the primary goal of the AI is not to win (although that could still happen), but rather to craft a story within the game in which the human will enjoy participating.
This sounds great in theory, but how does an AI engineer make this happen?  To tell a story, the AI needs to be concerned about more than the goal state.  The AI needs to consider the steps along the way and the quality of the narrative told by those steps.  The authors use the term trajectory to describe the set of states and transitions leading from a starting state to a goal state.  In order to provide an engaging story the engineer must have a method for finding moves which maximize the utility of a trajectory and they must have a method for evaluating the utility of the potential trajectories.  
To address the issue of searching for moves that provide the best trajectory, the authors suggest either a partial-order planning algorithm (which they did not discuss in detail) or a Targeted Trajectory Distribution Markov Decision Process (TTD-MDP).  A TTD-MDP will provide a probabilistic policy that gives a distribution over actions for a given state.  The key difference from a more traditional game AI agent is that it will optimize for a policy that matches a target over an entire trajectory rather than simply attempting to maximize the total expected discounted reward.  By seeding the system with a set of example trajectories that are considered desirable, the algorithm can efficiently search for similar trajectories.
Determining the utility of a given trajectory is more subjective but the authors provide a few examples of heuristics that could be used to estimate how interesting a trajectory is.  Pulling largely from dramatic practices, they provide examples of (or pointers to systems that have) ways to measure such things as suspense (for engagement), flow control (for story cohesion), and a discussion on dramatic arc, where tensions builds over time before reaching a climax.  Creating a utility function maximizes these characteristics (however appropriate for the context of the game being played) allows for a mathematical measurement of trajectory quality.
The paper is interesting in that much of the game industry has turned toward using games more as interactive cinematic adventures designed to be completed as opposed to in the past where finishing a game was an actual accomplishment.  Clearly, the ideas in this paper (at least conceptually, if not the exact technical approach) have become popular.  The idea of using “intelligent mistakes”, rather than random errors, to provide a competitive experience with humans feels very similar to a parent playing a game with a child and providing opportunities for the child to succeed even if they don’t totally “let them win”.  
The one section of the paper I was rather uncomfortable with was the case study on poker agents.  One of the ideas discussed there was essentially “stacking” the deck to provide dramatic outcomes.  While I understand the enhanced excitement or drama may make the game more enjoyable to play, the idea of manipulating the results of a game that relies on a large randomness component feels wrong.  It seems that focusing on using the player AI to tell a story (by crafting a realistic persona, perhaps) provides a good avenue for introducing a narrative in a way that doesn’t fundamentally alter the game.
In terms of follow-on, there are a couple of areas that may be interesting.  When the AI chooses a trajectory it would like to follow and makes a move in that direction, it requires the human to perform a specific action in order to continue along the optimal trajectory.  There seems like there is space for research into understanding the implications of human decisions in this system and determining ways to ensure the enjoyment/engagement remains high even when the human chooses an action that veers off the optimal trajectory.  Some ideas: limit the number of choices the human has, encourage the human to take the desired path with some sort of incentive, or modify the model to take into account user decision making (perhaps choose an action that leads towards multiple trajectories with high non-optimal utilities rather than an action that leads to the optimal trajectory but may lead to very low utility trajectories if the human chooses incorrectly). 